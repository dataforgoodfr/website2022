## Un serment d’Hippocrate pour toute personne travaillant avec la donnée : vers un engagement éthique des data scientists

**Le collectif Data for Good invite les data scientists et les spécialistes de la donnée à s’engager à respecter une charte éthique.**

Cette initiative a été lancée dans le cadre de la saison d'accélération 2018 de Data for Good, qui regroupe des bénévoles pendant trois mois pour mettre la data science au service de l’intérêt général à travers le développement de réflexions et de produits fonctionnels s'attaquant à des problèmes de société.

“*C’est un projet par et pour des data scientists, ouvert et bénévole*”, explique Soline Ledésert, web designer et membre du projet.

**Le projet a impliqué plus d’une centaine de data scientists et d’experts** qui collectent, stockent, traitent, modélisent, analysent des données et font de la prédiction dans le cadre de leur activité professionnelle. Ces data scientists travaillent dans des start-ups, des grandes entreprises, des cabinets de conseil, des PME, des administrations, ou sont indépendants ou chercheurs.

**La charte s’articule à la fois autour de principes éthiques fondamentaux et de bonnes pratiques d’utilisation des données.**

Les principes d’intégrité scientifique, de transparence, d’équité, de respect et de responsabilité sont mis en avant. Les engagements sont formulés à la première personne, comme dans le serment d’Hippocrate des médecins :

>« *Je veillerai à toujours m’assurer que des individus ou des groupes ne soient pas discriminés par rapport à des critères illégaux ou illégitimes, de façon directe ou indirecte, sur la base de mes travaux sur les données.* »

>« *J’exercerai mon activité professionnelle en respectant la vie privée et la dignité des personnes dans toutes leurs dimensions.* »

>« *J’assumerai mes responsabilités en cas de manquements ou de conflits d’intérêt et je donnerai l’alerte si des actes illégaux liés à des données sont constatés.* »

**Toute personne travaillant avec la donnée peut lire la charte et la signer publiquement sur le site.**

“*C’est un guide pratique que l’on peut utiliser à chaque étape de notre travail de data scientist et qui rappelle la dimension éthique et les limites à respecter*”, selon Sami Moustachir, data scientist et membre du projet.

La charte contient en effet une dimension opérationnelle à travers des conseils pratiques. Décrite comme une “check-list éthique”, elle concerne par exemple l’application de modèles algorithmiques, qui sont souvent assimilés à des boîtes noires :

>« *Je m'engage à …*

>*... prévoir les dérives possibles du modèle par rapport aux données dans le temps, de façon à éviter l'apparition de biais supplémentaires.*

>*... réfléchir à la performance et à l'interprétabilité de chaque modèle à disposition et, si possible, opter pour les modèles les plus explicables aux personnes concernées par les résultats.* »

**Un rappel de dispositions du Règlement Général sur la Protection des Données (RGPD) est également intégré à la charte** pour clarifier des notions essentielles telles que les « données personnelles » ou le « consentement ».

“*Ce guide permet de montrer comment évaluer nos pratiques par rapport aux grands principes éthiques et juridiques, mais aussi de les expliciter*”, explique Estelle Recuero, product manager et membre du projet.

**La charte va au-delà du cadre législatif** afin de promouvoir l’utilisation éthique des données et de prévenir de potentiels scandales liés aux données et à l’intelligence artificielle. 

L’objectif est de faire grandir la responsabilité individuelle et collective des data scientists en suscitant une réflexion et des échanges sur l’impact social de leur activité professionnelle.

## La charte

<details>
<summary>

Principe #1 - Interroger la **finalité** du projet, sa **légalité** et son possible **impact social et environnemental**.

</summary>
</details>
<details>
<summary>

Principe #2 - Veiller à ce que les **métriques à optimiser** soient pertinentes et **ne conduisent pas** le projet à avoir un impact social et environnemental négatif.

</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #3 - Faire mon possible pour que mes conditions de travail, en particulier le **temps de travail** qui m’est alloué, me permettent de mener avec les données un travail honnête et **le plus scientifique possible**.

</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #4 - Ne pas collecter ou utiliser de **données inutilement personnelles et/ou sensibles**.

</summary>
<div>



*Etape projet (2): Je collecte ou je dispose de données*

... et une « donnée sensible » ?

L’[article 9 du Règlement Général sur la Protection des Données (RGPD)](https://www.cnil.fr/fr/reglement-europeen-protection-donnees/chapitre2#Article9) prévoit que « le traitement des données à caractère personnel qui révèle l'origine raciale ou ethnique, les opinions politiques, les convictions religieuses ou philosophiques ou l'appartenance syndicale, ainsi que le traitement des données génétiques, des données biométriques aux fins d'identifier une personne physique de manière unique, des données concernant la santé ou des données concernant la vie sexuelle ou l'orientation sexuelle d'une personne physique sont interdits ».

</div>
</details>
<details>
<summary>

Principe #5 - Ce que les données que je collecte ou dont je dispose soient **exactes** et que je comprenne bien leur signification. pour cela, je m’engage à retracer autant que possible **l'origine** et le processus de création des données, ainsi que les éventuelles **modifications** qu'elles ont subies.

</summary>
<div>



*Etape projet (2): Je collecte ou je dispose de données*

Le droit prévoit un principe d'exactitude des données personnelles. celles-ci doivent être « exactes et, si nécessaire, tenues à jour ». celles qui seraient inexactes doivent être effacées ou rectifiées.

... selon l'[article 5 (d) du Règlement Général sur la Protection des Données (RGPD)](https://www.cnil.fr/fr/reglement-europeen-protection-donnees/chapitre2#Article5).

</div>
</details>
<details>
<summary>

Principe #6 - Ne pas collecter **des données dont je peux raisonnablement estimer qu’elles ne seront pas utiles** par rapport aux besoins du projet.

</summary>
<div>



*Etape projet (2): Je collecte ou je dispose de données*

Le droit prévoit un principe de minimisation, c'est-à-dire que les données à caractère personnel doivent être « adéquates, pertinentes et limitées à ce qui est nécessaire au regard des finalités pour lesquelles elles sont traitées ».

... selon l'[article 5 (c) du Règlement Général sur la Protection des Données (RGPD)](https://www.cnil.fr/fr/reglement-europeen-protection-donnees/chapitre2#Article5).

</div>
</details>
<details>
<summary>

Principe #7 - Ne pas **négliger des données potentiellement utiles au projet**, dans la limite des principes éthiques, afin de ne pas mettre en péril la robustesse et la pertinence des résultats de leur traitement.

</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #8 - Veiller à ce que les données dont j’ai la responsabilité soient **gérées et stockées en sécurité**.

</summary>
<div>



*Etape projet (2): Je collecte ou je dispose de données*

Le droit prévoit que les données personnelles doivent être sécurisées.

L’[article 32 du Règlement Général sur la Protection des Données (RGPD)](https://www.cnil.fr/fr/reglement-europeen-protection-donnees/chapitre4#Article32) prévoit que des mesures techniques et organisationnelles doivent être mises en place afin d’assurer la sécurité des données personnelles.

</div>
</details>
<details>
<summary>

Principe #9 - **communiquer**, ou sinon rappeler aux équipes compétentes, la nécessité de communiquer auprès des personnes concernées, l’usage qui sera fait de leurs données, de **la façon la plus claire, explicite et transparente possible**.

</summary>
<div>



*Etape projet (2): Je collecte ou je dispose de données*

Un tel principe de communication claire et explicite est prévu par le droit.

L'[article 12 du Règlement Général sur la Protection des Données (RGPD)](https://www.cnil.fr/fr/reglement-europeen-protection-donnees/chapitre3#Article12) oblige à informer les personnes d’une façon « concise, transparente, compréhensible » et adaptée.

Les [articles 13](https://www.cnil.fr/fr/reglement-europeen-protection-donnees/chapitre3#Article13) et [14](https://www.cnil.fr/fr/reglement-europeen-protection-donnees/chapitre3#Article14) du RGPD prévoient une liste conséquente d'informations à fournir aux personnes : l’identité du responsable du traitement, les finalités du traitement, les données concernées, les droits des personnes sur leurs données, etc…

</div>
</details>
<details>
<summary>

Principe #10 - Veiller à ce que le **consentement des personnes** dont je collecte les données soit obtenu dans des conditions loyales et transparentes pour eux. en cas de changements ultérieurs des conditions d'utilisation, veiller à ce que ces changements leur soient aussi communiqués clairement et efficacement, et ré-obtenir leur consentement dans des conditions loyales, explicites et transparentes pour eux.

</summary>
<div>

*Etape projet (2): Je collecte ou je dispose de données*

Le « consentement » a une définition légale.

L’[article 4 paragraphe 11 du Règlement Général sur la Protection des Données (RGPD)](https://www.cnil.fr/fr/reglement-europeen-protection-donnees/chapitre1#Article4) définit le consentement comme « toute manifestation de volonté, libre, spécifique, éclairée et univoque par laquelle la personne concernée accepte, par une déclaration ou par un acte positif clair, que des données à caractère personnel la concernant fassent l'objet d'un traitement ».

</div>
</details>
<details>
<summary>

Principe #11 - Veiller, lorsque j'élimine ou j'impute des valeurs manquantes ou aberrantes, à **ne pas introduire de biais supplémentaires** qui mèneraient à des résultats partiels ou faux. pour cela :

- je regarde la **distribution** des données à ma disposition ;
- je m'interroge sur **leurs potentiels biais**, notamment le biais de sélection ;
- je **justifie et documente** mon nettoyage.

</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #12 - Ne pas créer de données caractéristiques (“features”) qui équivaudraient à des données personnelles sensibles si leur usage peut entraîner des effets discriminatoires illégaux ou illégitimes (exemples : code postal, nom de famille, ...).

</summary>
<div>


*Etape projet (3): Je prépare et j’explore les données*

Ce point est l'objet d'une discussion.

Vous pouvez la lire sur [notre Framavox](https://framavox.org/d/hV4Zif7N/-viter-les-discriminations-en-cr-ant-des-features-de-contr-le-sensible). Ce point sera retravaillé pour la prochaine version du Serment.

</div>
</details>
<details>
<summary>

Principe #13 - Déterminer le **meilleur compromis entre la performance et l'interprétabilité** sur l’ensemble des modèles à disposition et autant que possible, opter pour **les modèles les plus simples à expliquer aux personnes concernées** (un modèle performant permettra de diminuer les risques d’erreur tandis qu’un modèle interprétable permettra de mieux justifier les résultats du modèle).

</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #14 - Paramétrer et **tester plusieurs modèles** en ne m’arrêtant pas au premier modèle et paramétrage qui me semblent bons.

</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #15 - Veiller à ce que le responsable du système puisse autant que possible **fournir une explication des résultats du modèle algorithmique** aux personnes concernées et ce d’autant plus s’il est légalement tenu d’expliquer ces décisions.

</summary>
<div>


*Etape projet (4): J'applique un ou des modèle(s) algorithmique(s)*

Le droit oblige à pouvoir expliquer le fonctionnement des algorithmes.

- L'[article 22 du Règlement Général sur la Protection des Données (RGPD)](https://www.cnil.fr/fr/reglement-europeen-protection-donnees/chapitre3#Article22) prévoit un principe selon lequel la personne concernée a le droit de s’opposer à ce qu’une décision sur elle soit prise uniquement sur le fondement d’un traitement automatisé. Certaines exceptions sont toutefois aménagées et le Règlement oblige à prendre des mesures appropriées pour protéger les personnes lorsqu’elles font l’objet d’une décision uniquement fondée sur un traitement automatisé.

- L’[article 10 de la loi française](https://www.legifrance.gouv.fr/affichTexteArticle.do;?idArticle=LEGIARTI000037090394&cidTexte=LEGITEXT000006068624&dateTexte=20180624) distingue deux cas :  

    ⁃    Dans le secteur privé, lorsqu’une décision est prise uniquement sur le fondement d’un traitement automatisé, l’auteur doit pouvoir expliquer les règles définissant le traitement et les caractéristiques de sa mise en oeuvre (sauf si cette explication est couverte par un secret).

    ⁃    Dans le secteur public, l’individu doit être informé que la décision a été fondée uniquement sur un algorithme et l’auteur de la décision doit pouvoir expliquer les règles définissant le traitement et les caractéristiques de sa mise en oeuvre.

- La [décision du Conseil Constitutionnel du 12 juin 2018](http://www.conseil-constitutionnel.fr/conseil-constitutionnel/francais/les-decisions/acces-par-date/decisions-depuis-1959/2018/2018-765-dc/decision-n-2018-765-dc-du-12-juin-2018.151485.html) précise dans quelles conditions les administrations peuvent avoir recours à des algorithmes pour prendre des décisions concernant les individus.

</div>
</details>
<details>
<summary>

Principe #16 - Mesurer le **biais** et la **variance** pour contrôler l'exactitude et la dispersion du résultat et documenter les **métriques d'erreur** retenues.

</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #17 - Garder un esprit critique par rapport aux **segments** issus d'un **algorithme de groupement** (“clustering”).

</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #18 - Prévoir et prévenir les **dérives possibles dans le temps du modèle** par rapport aux données, de façon à éviter l'apparition de biais supplémentaires.

</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #19 - Veiller à regarder les résultats dans leur ensemble (**non-partialité**) et à ne pas céder à un "**biais de confirmation**" (qui consisterait à voir ce à quoi je m'attendais). 

</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #20 - Vérifier l’**absence de discrimination** : vérifier si le modèle s’applique avec la même pertinence sur des **segments potentiellement discriminatoires** de la population traitée.

</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #21 - Communiquer ma démarche et mes résultats (ou leur absence) à mon client / mon équipe :

- en ne les **dénaturant** et en ne les **dissimulant pas**, notamment en choisissant une visualisation fidèle à l’ensemble des résultats
- en **garantissant la compréhension la plus exacte possible**, en optant pour les visualisations et explications les plus parlantes, en précisant les **précautions d’usage** à prendre avec ces résultats et leur interprétation.

![](https://hippocrate.s3.eu-west-3.amazonaws.com/b274b86d643440718773ec4c6d79fabd.png
)
</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #22 - Donner **l'alerte** si je constate une utilisation frauduleuse, illégale, illégitime, discriminatoire ou non-éthique des résultats.

</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #23 - Veiller à ce que les données ne soient pas conservées **plus longtemps que ce qui est nécessaire** pour l’application telle que définie pendant le projet.

</summary>
<div>


*Etape projet (7): Je termine le projet*

Un principe de conservation limitée dans le temps est prévu par le droit.

Selon l’[article 5 (e) du Règlement Général sur la Protection des Données (RGPD)](https://www.cnil.fr/fr/reglement-europeen-protection-donnees/chapitre2#Article5), les données à caractère personnel doivent être « conservées sous une forme permettant l'identification des personnes concernées pendant une durée n'excédant pas celle nécessaire au regard des finalités pour lesquelles elles sont traitées ; les données à caractère personnel peuvent être conservées pour des durées plus longues dans la mesure où elles seront traitées exclusivement à des fins archivistiques dans l'intérêt public, à des fins de recherche scientifique ou historique ou à des fins statistiques conformément à l'article 89, paragraphe 1, pour autant que soient mises en œuvre les mesures techniques et organisationnelles appropriées requises par le présent règlement afin de garantir les droits et libertés de la personne concernée ».

</div>
</details>
<details>
<summary>

Principe #24 - **documenter au maximum les données et leurs traitements** afin d’en garantir l’**explicabilité** et la **reproductibilité**.

</summary>
<div>


</div>
</details>
<details>
<summary>

Principe #25 - Anticiper les **usages** qui pourraient être faits de mon travail à moyen et long terme et faire mon possible pour garder sur lui un **droit de regard** et une **possibilité d’action**.

</summary>
<div>


</div>
</details>

**À propos de Data for Good**

Data for Good est une communauté de data scientists et développeurs volontaires mettant leurs compétences au profit de la résolution de problèmes sociaux. 

Pour suivre Data for Good :

- sur Facebook : [DataForGoodfr](https://www.facebook.com/dataforgoodfr/)
- sur Twitter :  [@DataForGood_FR](https://twitter.com/DataForGood_FR)
- sur le site [www.dataforgood.fr](www.dataforgood.fr)

Contact presse : 
- [**contact@hippocrate.tech**](mailto:contact@hippocrate.tech)
- [**hellodataforgood@gmail.com**](mailto:hellodataforgood@gmail.com)
